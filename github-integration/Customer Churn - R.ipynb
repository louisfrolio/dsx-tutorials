{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# DSX Hands-on Workshop\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## A bit about Jupyter notebook cell types.\n\nThe behavior of a cell is determined by a cell\u2019s type. \n\nThe different types of cells include:\n\n**Code**: Where you can edit and write new code.\n\n**Markdown**: Where you can document the computational process. You can input headings to structure your notebook hierarchically.\n\n**Raw NBConvert**:  Where you can write output directly or put code that you don\u2019t want to run. Raw cells are not evaluated by the notebook.\n\nFor the purpose of this lab, a heading will be added but all further notes will be inline with the code by using #.  An example of using Markdown will follow.\n\nIf you want to learn more about markdown then check this out:\n[Mark Down Cheatseet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Add Markdown Title Here", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 1
        }, 
        {
            "source": "## R Libraries\n\nMany R functions come in packages, which are free libraries of code written by R's active user community.  There are thousands of helpful R packages but this lab will only require the following:\n\n**caret**: Package of useful functions that help streamline the model building and evaluation process.\n\n**randomForest**: Classification and regression based on a forest of trees using random inputs.\n\n**rpart**: Recursive partitioning for classification, regression and survival trees. An implementation of most of the functionality of the 1984 book by Breiman, Friedman, Olshen and Stone.\n\n**rpart.plot**:Plot 'rpart' models. Extends plot.rpart() and text.rpart() in the 'rpart' package.\n\n**e1071**: Functions for latent class analysis, short time Fourier transform, fuzzy clustering, support vector machines, shortest path computation, bagged clustering, naive Bayes classifier.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Install required libraries if not already present\n# This step can take up to 1-2 minutes.\n\nif(!require(caret)){\n  install.packages(\"caret\")\n  print ('Package [caret] successfully installed.')\n  library(caret)\n  print ('[caret] loaded.')\n} else {\n  print('Package [caret] already installed.')\n  library(caret)\n  print ('[caret] loaded.')\n}\n\nif(!require(randomForest)){\n  install.packages(\"randomForest\")\n  print ('Package [randomForest] successfully installed.')\n  library(randomForest)\n  print ('[randomForest] loaded.')\n} else {\n  print('Package [randomForest] already installed.')\n  library(randomForest)\n  print ('[randomForest] loaded.')\n}\n\nif(!require(rpart)){\n  install.packages(\"rpart\")\n  print ('Package [rpart] successfully installed.')\n  library(rpart)\n  print ('[rpart] loaded.')\n} else {\n  print('Package [rpart] already installed.')\n  library(rpart)\n  print ('[rpart] loaded.')\n}\n\nif(!require(rpart.plot)){\n  install.packages(\"rpart.plot\")\n  print ('Package [rpart.plot] successfully installed.')\n  library(rpart.plot)\n  print ('[rpart.plot] loaded.')\n} else {\n  print('Package [rpart.plot] already installed.')\n  library(rpart.plot)\n  print ('[rpart.plot] loaded.')\n}\n\nif(!require(e1071)){\n  install.packages(\"e1071\")\n  print ('Package [e1071] successfully installed.')\n  library(e1071)\n  print ('[e1071] loaded.')\n} else {\n  print('Package [e1071] already installed.')\n  library(e1071)\n  print ('[e1071] loaded.')\n}", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Loading required package: caret\nLoading required package: lattice\nLoading required package: ggplot2\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[1] \"Package [caret] already installed.\"\n[1] \"[caret] loaded.\"\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Loading required package: randomForest\nrandomForest 4.6-12\nType rfNews() to see new features/changes/bug fixes.\n\nAttaching package: \u2018randomForest\u2019\n\nThe following object is masked from \u2018package:ggplot2\u2019:\n\n    margin\n\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[1] \"Package [randomForest] already installed.\"\n[1] \"[randomForest] loaded.\"\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Loading required package: rpart\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[1] \"Package [rpart] already installed.\"\n[1] \"[rpart] loaded.\"\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Loading required package: rpart.plot\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[1] \"Package [rpart.plot] already installed.\"\n[1] \"[rpart.plot] loaded.\"\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Loading required package: e1071\nWarning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n\u201cthere is no package called \u2018e1071\u2019\u201dUpdating HTML index of packages in '.Library'\nMaking 'packages.html' ... done\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[1] \"Package [e1071] successfully installed.\"\n[1] \"[e1071] loaded.\"\n"
                }
            ], 
            "execution_count": 2
        }, 
        {
            "source": "## Reproducible Results", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Ensure the process is reproducible\n# Generally, in statistics, samples are chosen at random.  A random number generator \n# is used to select the samples and is based off of a seed value.  The seed is \n# explicitly set so results are reproducible. To ensure everyone retrieves the same \n# results in this lab, the seed value was randomly chosen as 3482.\nset.seed(3842)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 3
        }, 
        {
            "source": "## Bluemix Object Storage Connectivity", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Placeholder for R Data Frame Auto-code\n# custDataRaw\nlibrary(\"aws.s3\")\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share your notebook.\nSys.setenv(\"AWS_ACCESS_KEY_ID\" = \"b36fcc869ac5455a85d7a8e87fb4f183\", \"AWS_SECRET_ACCESS_KEY\" = \"5372712d0fd9b9dc276f8be3d4eaaeddfd62bf38bbabcb58\")\nurl <- \"s3-api.us-geo.objectstorage.service.networklayer.com\"\nbucket <- \"customerchurnredition-donotdelete-pr-fgzmnpqvqkdobt\"\nheaders <- list(`x-amz-content-sha256`=\"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\")\n\nobj <- s3HTTP(\n    verb = \"GET\",\n    bucket = bucket,\n    headers = headers,\n    path = \"customer_churn.csv\",\n    key = Sys.getenv(\"AWS_ACCESS_KEY_ID\"),\n    secret = Sys.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n    check_region = FALSE,\n    base_url = url)\n\ndf.data.1 <- read.csv(text = rawToChar(obj$content))\nhead(df.data.1)\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 4
        }, 
        {
            "source": "# Primary data set row count\ncat(sprintf(\"[custDataRaw] has %d rows:\\n\", nrow(custDataRaw)))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "error", 
                    "evalue": "Error in nrow(custDataRaw): object 'custDataRaw' not found\n", 
                    "traceback": [
                        "Error in nrow(custDataRaw): object 'custDataRaw' not found\nTraceback:\n", 
                        "1. cat(sprintf(\"[custDataRaw] has %d rows:\\n\", nrow(custDataRaw)))", 
                        "2. sprintf(\"[custDataRaw] has %d rows:\\n\", nrow(custDataRaw))", 
                        "3. nrow(custDataRaw)"
                    ], 
                    "ename": "ERROR"
                }
            ], 
            "execution_count": 5
        }, 
        {
            "source": "# Summary Stats for entire data set\nsummary(custDataRaw)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Create index of data rows to faciliate partitioning\n# The createDataPartition function will randomly pick 90% of the rows which will be used for training/testing data sets\n# 10% will be left out for a validation data set\ntrainIndex_temp <- createDataPartition(y= custDataRaw$CHURN, p=0.9, list = FALSE)\n\n# 10% data goes in here (validation)\n# Notice the \"-\" symbol to indicate \"not\" the 90%\nvalidation  <- custDataRaw[-trainIndex_temp,]\n\n# This now becomes our working data for training and testing\ntemp_hold <- custDataRaw[trainIndex_temp,]\n# Rename it to something friendly\ncustDataRaw <- temp_hold\n\n# The remaining data will be split again for training and testing data\ntrainIndex <- createDataPartition(y= temp_hold$CHURN, p=0.8, list = FALSE)\ntrain <- temp_hold[trainIndex,]\ntest <- temp_hold[-trainIndex,]\n# 80% for training\n# 20% for testing\n\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Training and Testing data sets row counts\ncat(sprintf(\"[train] has %d rows:\\n\", nrow(train)))\ncat(sprintf(\"[test] has %d rows:\\n\", nrow(test)))\ncat(sprintf(\"[validation] has %d rows:\\n\", nrow(validation)))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Decision Tree Classifier\n\nDecision tree learning uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) \nto conclusions about the item's target value (represented in the leaves). It is one of the predictive modelling approaches used in statistics, \ndata mining and machine learning. \n\nIf you want to learn more about the decision trees then check this out:\n[Decision Tree Learning](https://en.wikipedia.org/wiki/Decision_tree_learning)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Using the training data (train), create a classification tree.\n# The target is \"CHURN\", the predictors are every other variable except ID.\n# The target is cast from boolean to a character for ease of model interpretation.\n\nfitCART <- rpart(as.character(CHURN) ~ Gender + Status + Children + Est.Income +\n                 Car.Owner + Age + LongDistance + International + Local +\n                 Dropped + Paymethod + LocalBilltype + LongDistanceBilltype +\n                 Usage + RatePlan,\n             data = train,\n             method=\"class\")\n\n# The resulting model is placed into an object called \"fitCart\"", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# The rpart.plot library helps us visualize the resulting tree.\nrpart.plot(fitCART)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "Each node shows\n- the predicted class (CHURN)\n- the predicted probability of CHURN\n- the percentage of observations in the node", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Using the \"predict\" function we measure our model's performance using the test data\nprediction <- predict(fitCART,test,type=\"class\")", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Show side by side, the actual outcome vs. the predictied outcome\nfinalResults <- data.frame(Actual = test$CHURN, Predicted = prediction)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Taking a peek at the resulting data frame\nhead(finalResults[order(finalResults$Actual, decreasing=TRUE), ], 100)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Confusion Matrix\nA confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known. The confusion matrix itself is relatively simple to understand, but the related terminology can be confusing.\n\nIf you want to learn more about the confusion matrix then check this out:\n[Confusion Matrix Cheatseet](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Overall, how well did our model perform?\nconfusionMatrix(prediction, test$CHURN)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Random Forest Classifier\n\nRandom forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set.\n\nIf you want to learn more about Random Forests then check this out:\n[Random Forests](https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm)\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "fitRandomForests <- randomForest(as.factor(CHURN) ~ Gender + Status + Children + Est.Income +\n                    Car.Owner + Age + LongDistance + International + Local +\n                    Dropped + Paymethod + LocalBilltype + LongDistanceBilltype +\n                    Usage + RatePlan,\n                    data=custDataRaw,\n                    importance=TRUE,\n                    ntree=100,\n                    mtry=3\n                    )", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# A nice feauture of Random Forests is that it provides an easy lens into the most important features.\nvarImpPlot(fitRandomForests, \n           sort=T,\n           main=\"Variable Importance\",\n           n.var=13)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "There are two types of importance measures produced with Random Forests. Accuracy (MeanDecreaseAccurary) tests to see how worse the model performs without each variable, so a high decrease in accuracy would be expected for very predictive variables. Gini (MeanDecreaseGini) digs into the mathematics behind decision trees, but essentially measures how pure the nodes are at the end of the tree. Again it tests to see the result if each variable is taken out and a high score means the variable was important.\n\nPlease make a note of the top 10 variables as indicated by **MeanDecreaseAccuracy**\n\n1.\n\n2.\n\n3.\n\n4.\n\n5.\n\n6.\n\n7.\n\n8.\n\n9.\n\n10.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Plotting Random Forests' trees is complex and can be misleading.  However, we are able to plot the Out of Bag Error Rate (OOB), the FALSE, and TRUE error rates as a function of the # of trees generated.\nplot(fitRandomForests, main=paste(\"Error Rate vs. # Trees ( mtry =\",fitRandomForests$mtry,\")\"), \n     type=\"l\", \n     col.main=\"black\",\n     lwd=2,\n     lty=1);\nlegend(\"top\", colnames(fitRandomForests$err.rate),col=1:4,\n       cex=0.8, fill=1:5, lwd=1, bty=\"n\")", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Overall, how did our Random Forests model perform\nprint(fitRandomForests)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Let's test our model with a small random sample of the overall data set\nrandomForestsPredictResponse <- predict(fitRandomForests, validation)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Overall model performance was excellent on a small sampling of data\nconfusionMatrix(randomForestsPredictResponse,\n                reference=validation$CHURN)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# END OF NOTEBOOK EXCERCISE", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "R", 
            "name": "r", 
            "language": "R"
        }, 
        "language_info": {
            "mimetype": "text/x-r-source", 
            "version": "3.4.2", 
            "name": "R", 
            "pygments_lexer": "r", 
            "file_extension": ".r", 
            "codemirror_mode": "r"
        }
    }, 
    "nbformat": 4
}